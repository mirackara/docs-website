---
title: Understand and manage data ingest
tags:
  - Ingest and manage data
  - Manage data
  - Data Ingest Governance
metaDescription: 'How to understand and manage your New Relic data ingest.'
redirects:
  - /docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic
  - /docs/manage-data-coming-new-relic
  - /docs/telemetry-data-platform/get-started/manage-data/manage-data-coming-in
  - /docs/manage-data-coming-in
  - /docs/telemetry-data-platform/get-data-new-relic/manage-data/manage-data-coming-new-relic
  - /telemetry-data-platform/get-started/manage-data/manage-data-coming-in
---

import accountsDataIngestUI from 'images/accounts_screenshot-full_data-ingest-UI.png'

import accountsFacetUsageData from 'images/accounts_screenshot-crop_facet-usage-data.png'

You may want to manage your New Relic data ingest for several reasons, including: 

* Removing unwanted data
* Managing [data ingest costs](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/data-ingest-billing)  

## Data ingest UI [#ui]

The **Data ingestion** tab is located in the [Data management UI](/docs/data-apis/manage-data/manage-your-data). The data ingestion UI shows a summary of your usage by data source. For organizations with multiple accounts, you can also view the usage of specific accounts. 

To see the underlying NRQL query used to create that chart, click **View query**.

<img
  title="Data ingest UI"
  alt="Data ingest UI"
  src={accountsDataIngestUI}
/>

<figcaption>
  From the [user menu](/docs/accounts/accounts-billing/general-account-settings/intro-account-settings), select **Manage your data**.
</figcaption>

For a video showing a brief tour of the other account management UIs, see [Account settings](/docs/accounts/accounts-billing/general-account-settings/intro-account-settings/#video-tour).

## Estimate future data ingest [#estimate]

If you're trying to estimate your future data ingest, see this [blog post on estimating data ingest](https://newrelic.com/blog/nerdlog/estimate-data-cost).

## Manage ingest and avoid ingest spikes [#manage]

How you manage your New Relic data will depend on a lot of factors specific to your organization and your needs. That said, here are some general tips for managing data ingest and avoiding unexpected data ingest charges: 

* Assign someone, or several people, to be in charge of reviewing and managing your New Relic data. Ensure they understand the [data-related billing factors](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/data-ingest-billing).  
* Make it a practice to occasionally review the data ingestion UI to understand the amount and sources of your data.
* When you install or activate a new tool, that is a good time to monitor your data ingest. 
* If you're concerned about specific scenarios causing sudden spikes in data, you can set up an alert condition to alert you if that occurs. For tips on that, see [Usage queries](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts).

Some ideas for steps for optimizing your data ingest: 

* See our docs on common, popular routes for reducing data ingest
* See our [Observability maturity guide to optimizing data ingest](/docs/new-relic-solutions/observability-maturity/operational-efficiency/intro-data-governance).  

## Data ingestion sources [#sources-list]

The [data ingestion UI](#data-ingest-ui) chart shows you a high level breakdown of your billable data usage. The table below explains those sources. In this table, "usage metric group" refers to the value of that source's `usageMetric` attribute value on the `NrConsumption` event.

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Data sources
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Metrics
      </td>

      <td>
        In the data ingestion chart, **Metrics** is a combination of two types of metrics: [metric timeslice data](/docs/data-apis/understand-data/new-relic-data-types/#timeslice-data) and [dimensional metrics](/docs/data-apis/understand-data/new-relic-data-types/#dimensional-metrics).

        Usage metric group: `MetricsBytes`.

        Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days.

        You are only billed for the initial ingest volume. You are not billed for subsequent rollups.
      </td>
    </tr>

    <tr>
      <td>
        APM
      </td>

      <td>
        This includes [APM events](/docs/insights/insights-data-sources/default-data/apm-default-events-insights), like `Transaction` and `TransactionError`.

        Usage metric group: `ApmEventsBytes`.
      </td>
    </tr>

    <tr>
      <td>
        Infrastructure
      </td>

      <td>
        Includes several categories of [infrastructure monitoring events](/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-events), described below.
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure host data.

        Usage metric group:`InfraHostBytes`.

        Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data.
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure process data stored in `ProcessSample`.

        Usage metric group: `InfraProcessBytes`.

        Data related to each process running on the hosts running the infrastructure agent. This feature is turned off by default. For more information, see [Process metrics](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#enable-process-metrics).
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure integrations.

        Usage metric group: `InfraIntegrationBytes`.

        Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP.
      </td>
    </tr>

    <tr>
      <td>
        Logging
      </td>

      <td>
        Includes logs and any `Log_<value>` custom data partition created.

        Usage metric group: `LoggingBytes`.

        Log records are stored on the `Log` data type by default. Additional custom data partitions will create new data types, which are always prefixed with `Log_` and are counted as part of the overall set of log data stored.

        With `LogExtendedRecord`, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data.

        As of September 2021, log storage as blobs replaces `LogExtendedRecord`. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our [log blobs docs](/docs/logs/log-management/ui-data/long-logs-blobs).
      </td>
    </tr>

    <tr>
      <td>
        Default
      </td>

      <td>
        [Custom events](/docs/insights/insights-data-sources/custom-data/report-custom-event-data).

        Usage metric group: `CustomEventsBytes`
      </td>
    </tr>

    <tr>
      <td>
        Mobile events
      </td>

      <td>
        [Mobile events](/docs/insights/insights-data-sources/default-data/mobile-default-events-insights), including the general `Mobile` event, `MobileRequestError`, `MobileBreadcrumb`, `MobileSession`, `MobileHandledException`, `MobileCrash`, `MobileRequest`, and `MobileJavaScriptError`.

        Usage metric group: `MobileEventsBytes`.
      </td>
    </tr>
    <tr>
      <td>
        Tracing
      </td>

      <td>
        Usage metric group: `TracingBytes`. This includes the `Span` data type and OpenTelemetry's `SpanEvent`. You are not charged for `DistributedTraceSummary` events.
      </td>
    </tr>

    <tr>
      <td>
        Browser events
      </td>

      <td>
        [Browser events](/docs/insights/insights-data-sources/default-data/browser-default-events-insights), including the namespaces of `Browser`, `Browser:EventLog`, `Browser:JSErrors`, and `PcvPerf` (PageView timing).

        Usage metric group: `BrowserEventsBytes`.
      </td>
    </tr>

    <tr>
      <td>
        Lambda
      </td>

      <td>
        [AWS Lambda events](/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure).

        Usage metric group: `ServerlessBytes`.
      </td>
    </tr>
  </tbody>
</table>

## Understand where data is coming from [#get-ingest-detail]

You can inspect your data ingest to gain more information about your ingest health.

From the data ingestion UI page, you can analyze your usage in more detail. Spending some time understanding your ingested data and where it comes from and how it changes over time can be valuable. You'll know your ingest anomalies, and you'll be able to more easily spot anomalies, like ingest spikes, and understand their source.

On the data ingestion chart, time is on the X axis and the bands representing data sources are located along the Y axis. Click on a data source band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. 

<img
  title="data-facet.png"
  alt="screenshot of data facet selection"
  src={accountsFacetUsageData}
/>

<figcaption>
  This image shows the data source band for June 15 right before it's clicked.
</figcaption>

A modal opens with the account, data source, and facet selected. You can do a handful of things on this page:

* Change the account, data source, or facet you want to drill down into.
* Change the time range.
* Review the results of the query in chart form. The chart displays the top 15 results for the facet query.
* Open the NRQL query in the **Query builder** where you'll find additional facets that you can use.

For more about creating more detailed queries:

* Learn some [NRQL basics](/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/).
* See some [example usage-related queries](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/#data-queries).

## Stream ingested data [#stream]

For more about streaming ingested data to other sources, see [Streaming export](/docs/apis/nerdgraph/examples/nerdgraph-streaming-export). 

## Data from multiple data center regions [#data-centers]

If you have accounts in multiple data center regions, [learn more about how to understand your usage](/docs/accounts/accounts-billing/account-setup/choose-your-data-center#account-structure).

## How ingested data is broken down

Some of the usage data in this UI can vary depending on your account. This information is intended to help you understand how we're working with your ingest data:

* The chart on the **Data ingestion** page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem.
* If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a one hour period.
* The ingest value provided on the main **Data ingestion** chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate.

## Set alerts for data use [#set-alerts]

For how to set alerts that will notify you when you're reaching data ingest levels you don't want to cross, see [Query and alert on usage data](/docs/accounts/accounts-billing/new-relic-one-pricing-users/usage-queries-alerts). For example, you might set an alert on logs, which can accumulate quickly in an active system.

## Reduce your data ingest [#adjust-ingest]

All of the tools you use to report data to New Relic have various configuration options for adjusting the data reported. We'll give some of the more common methods for reducing data ingest here, but we recommend looking at the docs for the specific tools you're using to learn other options. 

### Drop unwanted data [#drop-data]

On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional [data dropping rules](/docs/accounts/accounts/data-management/drop-data-using-nerdgraph) yourself. For how to drop log data, see [Drop log data](/docs/logs/new-relic-logs/ui-data/drop-data-drop-filter-rules).

### Disable agents and integrations [#disable]

If you have agents or integrations that you don't need at all, you can uninstall/delete those tools. For instructions, see the specific docs for that tool.

### Adjust APM data ingest [#adjust-apm-ingest]

Options for adjusting APM data include:

* Configure the sampling rate for transaction events. See agent configurations for [Java](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Transaction_Events), [.Net](/docs/apm/agents/net-agent/configuration/net-agent-configuration), [Go](/docs/apm/agents/go-agent/configuration/go-agent-configuration#transaction-events-settings), [NodeJS](/docs/apm/agents/nodejs-agent/installation-configuration/nodejs-agent-configuration), [PHP](https://docs.newrelic.com/docs/apm/agents/php-agent/configuration/php-agent-configuration), [Python](/docs/apm/agents/python-agent/configuration/python-agent-configuration), and [Ruby](/docs/apm/agents/ruby-agent/configuration/ruby-agent-configuration).  
* [Set appropriate Apdex scores](/docs/apm/new-relic-apm/apdex/change-your-apdex-settings/), for example, for frequency of traces.
* Optimize [custom instrumentation](/docs/apm/agents/manage-apm-agents/agent-data/custom-instrumentation/) and/or [custom metrics](/docs/apm/agents/manage-apm-agents/agent-data/collect-custom-metrics/).

### Adjust infrastructure data ingest [#adjust-infra-ingest]

Options for adjusting infrastructure data include:

* Adjust [sampling rate](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings#samples-variables) for network, storage, and system events.
* [Disable process metrics](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#enable-process-metrics).
* Adjust polling intervals:
  * [Polling for cloud integrations](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations).
  * For on-host integrations: edit the configuration file for a specific integration.
* [Control the reporting of specific attributes](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#include-matching-metrics).
* Manage [Kubernetes events integration](/docs/kubernetes-pixie/kubernetes-integration/kubernetes-events/install-kubernetes-events-integration/#install).

### Adjust log data ingest [#adjust-log-ingest]

Options for adjusting log data ingest include:

* [Automatic logs in context](/docs/logs/logs-context/disable-automatic-logging): Disable or enable via the UI or API, or adjust client-side configuration settings.
* [Log data forwarding](/docs/logs/forward-logs/enable-log-management-new-relic): Adjust the log forwarder configuration to filter log events on the sending side.
* [Drop log data](/docs/logs/ui-data/drop-data-drop-filter-rules): Manage data ingest via the UI or API.

## Optimize your data ingest [#optimize-ingest]

We also have an [in-depth tutorial on how to optimize data ingest](/docs/new-relic-solutions/observability-maturity/operational-efficiency/intro-data-governance).  